【神经网络】7 LVQ 网络

学习向量量化，英文名 learning vector quantization，简称 LVQ，是将竞争学习思想和有监督学习算法相结合的神经网络模型，克服了自组织网络采用无监督学习算法带来的缺乏分类信息的弱点，是 SOM 网络的一种有监督形式的扩展。

# 7 LVQ网络
## 7.1 网络模型
LVQ 是有监督学习和无监督学习的**有机结合**，属于**有监督**学习。

**(1) 基本概念**

* 量化 - 针对标量，指将信号的连续取值或大量可能的离散取值近似为有限个或减少的离散值的过程。
* 向量量化 - 对标量化的扩展，将高维空间的若干不同的区域，对每个区域确定一个中心向量作为聚类中心，用来代表该区域内的向量。

**(2) 拓补结构**

LVQ 的网络拓补结构如图 7.1 所示，有输入层、竞争层和输出层三层组成。输入层有 $$n$$ 个神经元，与竞争层全连接；竞争层有 $$m$$ 个神经元，分组线性排列；输出层有 $$l$$个 神经元，与竞争层的一组神经元连接，权值固定为$$1$$。

LVQ 网络各层的数学描述如下：

输入层输入向量：$$X = (x\_1, x\_2, \cdots, x\_n)^T$$;

竞争层输出向量：$$Y = (y\_1, y\_2, \cdots, y\_m)^T, \; \; y_j \in \\{0,1\\}, \; \; j = 1,2,\cdots,m$$

输出层输出向量：$$O = (o\_1, o\_2, \cdots,o\_l)^T$$

网络的期望输出：$$d=(d\_1,d\_2, \cdots, d\_l)^T$$

输入层到竞争层的权值矩阵：$$W^1=(W\_1^1,W\_2^1, \cdots, W\_j^1, \cdots, W\_m^1)$$

竞争层到输出层的权值矩阵：$$W^2=(W\_1^2,W\_2^2, \cdots, W\_k^2, \cdots, W\_l^2)$$

<div style="max-width:50%;margin:auto;text-align:center;">![](/static/images/img_art/001553331341870ec76975f54004219bea0e72e2270f9dd000.png)
图7.1 学习向量量化网络

</div>

**(3) 转移函数与学习规则**

LVQ 网络的学习规则结合了竞争学习和有监督学习规则。

竞争层的神经元采用胜者为王竞争学习规则，转移函数使获胜神经元输出$$1$$，其余输出$$0$$。

输出层采用有监督学习，其作用是对竞争层的输出分类进行细调，权值$$W^2$$在一开始就已经给定（无需学习规则），使得竞争层的一组神经元只连接输出层的一个神经元，对应权值为$$1$$，其余权值为$$0$$，正如图 7.1 所展示的那样，输出层转移函数就是$$O = (W^2)^TY$$。

总的来说，输出层到竞争层就是前面提到的无监督竞争学习网络，而输出层只是对竞争学习分类结果的一个细调、综合。因此，称竞争层学习得到的类为子类，输出层学习得到的类称为目标类，对应到权值矩阵$$W^2$$，其列表示类，行表示子类。

## 7.2 算法设计
**(1) 原理**

LVQ 算法原理与竞争学习原理类似，将样本数据沿输入层输入，经过竞争层的竞争学习，获胜神经元可以输出和调整权值，含有获胜神经元的那组子类们将结果传递到输出层，然后输出层计算并输出获胜神经元所属类别。

<div style="max-width:40%;margin:auto;text-align:center;">![](/static/images/img_art/001553390168793561880487bf9435abf4923f1d820d9d6000.png)
图7.2 学习向量量化的权值调整

</div>

通过比较期望输出与实际输出来调整权值，如图 7.2 所示，若分类正确，则将获胜神经元的权向量向输入向量方向调整，若分类错误，则向相反方向调整。

**(2) 算法**

> (1) 数据初始化
> &nbsp; &nbsp; &nbsp; &nbsp; 初始化竞争层权值矩阵$$W^1$$为小随机数，确定输出层权值矩阵$$W^2$$，设置最大训练次数$$K$$，建立学习率函数$$\eta (k)=\eta(0) \left ( 1 - k/K \right )$$。
> &nbsp; &nbsp; &nbsp; &nbsp; 由于接下来用欧氏距离寻找获胜神经元，故不用对权值向量和输入向量进行归一化处理。

> (2) 输入样本
> &nbsp; &nbsp; &nbsp; &nbsp; 输入一个样本向量。

> (3) 寻找获胜节点
> &nbsp; &nbsp; &nbsp; &nbsp; 基于欧氏距离按照以下公式寻找获胜节点$$j^*$$。
```katex
\displaystyle
\lVert X - W_{j^*}^1 \rVert = \min _j \lVert X - W_j^1 \rVert \; \; j = 1,2,\cdots,M
```

> (4) 调整权值
> &nbsp; &nbsp; &nbsp; &nbsp; 根据分类结果是否正确，按照不同的规则调整获胜神经元的权值，非获胜神经元权值保持不变。
> &nbsp; &nbsp; &nbsp; &nbsp; 实际输出等于期望输出，向输入样本方向调整：
```katex
\displaystyle
W_{j^*}^1 (k+1) = W_{j^*}^1 (k) + \eta(k) \left [ X - W_{j^*}^1(k) \right ]
```

> &nbsp; &nbsp; &nbsp; &nbsp; 实际输出不等于期望输出，逆输入样本方向调整：
```katex
\displaystyle
W_{j^*}^1 (k+1) = W_{j^*}^1 (k) - \eta(k) \left [ X - W_{j^*}^1(k) \right ]
```

> (5) 输入下一个样本，重复步骤 (2) 至 (4) 。样本训练一轮后，令$$k=k+1$$，开始新一轮训练，直到达到最大训练次数$$K$$。

**(3) 实现**

实践是检验真理的唯一标准，下面来考虑一下这个问题：

设输入为二维向量，共有 10 个输入样本，分别为

```katex
\left \{ (-6,0), (-4,2), (-2,-2), (0,1), (0,2), (0,-2), (0,1), (2,2), (4,-2), (6,0) \right \}
```

样本类别依次为

```katex
[1 1 1 2 2 2 2 1 1 1]
```

试设计一个 LVQ 网络对样本进行分类。下面用 Python 设计一个 LVQ 网络玩玩。

先导入相关包，然后准备数据，对于二维数据，我们可以将它们画在图 7.3(a) 上感受一下，我们要做的就是将其分成图 7.3(b) 的类别。

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

'''数据准备'''
X = np.array([[-6,0], [-4,2], [-2,-2], [0,1], [0,2], [0,-2], (0,1), [2,2], [4,-2], [6,0]]).T
D = np.array([1, 1, 1, 2, 2, 2, 2, 1, 1, 1]) - 1

# 绘图 - 原始数据
plt.figure(1)
plt.scatter(X[0,:],X[1,:])
plt.figure(2)
plt.scatter(X[0,D==0],X[1,D==0])
plt.scatter(X[0,D==1],X[1,D==1])
plt.show()
```

然后设计 LVQ 网络结构，输入层节点个数与输入模式维数相匹配，竞争层个数随意（注意，会影响网络训练效果），输出层个数与要分类的个数匹配。

<div style="text-align:center;background-color:#999;width:max-content;margin:auto;margin-bottom: 1rem;">![](/static/images/img_art/001554597879130e977e774f75a4389bbad332bbcf347af000.png) ![](/static/images/img_art/0015545978876681b64773caf0044cbab1ceb6848b5f371000.png)
图7.3 数据分布图

</div>

```python
'''网络设计'''
P = X.shape[1] # 输入模式数
n = X.shape[0] # 输入层节点数
m = 4*n # 竞争层节点数
l = 1 # 输出层节点数
W1 = np.random.random([n,m])/10 # 竞争层权值矩阵
W2 = np.zeros([m,l])
W2[1::2, 0] = 1 # 输出层权值矩阵
K = 50 # 最大训练次数
eta = lambda k : 0.7*(1-k/K) # 学习率函数
```

然后就可以开始训练网络了 (￣▽￣)~*

```python
'''网络训练'''
k = 0
while k<K:
    i = 0
    #pdb.set_trace()
    while i<P:
        x = X[:,i].reshape(n,1) # 输入样本向量
        d = D[i].reshape(l,1) # 期望输出向量
        ind = np.argmin(np.diag((x-W1).T.dot(x-W1))) # 寻找获胜节点
        y = np.zeros((m,1)) # 竞争层输出向量
        y[ind] = 1
        o = W2.T.dot(y) # 输出层输出向量
        # 判断权值调整方向
        direction = 0
        if np.sum((o-d).T.dot(o-d)) == 0:
            direction = 1 # 正向
        else:
            direction = -1 # 反向
        W1[:,ind] = W1[:,ind] + direction*eta(k) * (x.reshape(n) - W1[:,ind]) # 调整权值
        i += 1 # 继续下一个模式
    k += 1
```

然后测试训练成果：

```python
'''网络输出'''
i = 0
while i<P:
    x = X[:,i].reshape(n,1) # 输入样本向量
    ind = np.argmin(np.diag((x-W1).T.dot(x-W1))) # 寻找获胜节点
    y = np.zeros((m,1)) # 竞争层输出向量
    y[ind] = 1
    o = W2.T.dot(y) # 输出层输出向量
    print('模式 %d 预测类别：%d，实际类别：%d' % (i,o,D[i]))
    i += 1
```

	模式 0 预测类别：0，实际类别：0
	模式 1 预测类别：0，实际类别：0
	模式 2 预测类别：0，实际类别：0
	模式 3 预测类别：1，实际类别：1
	模式 4 预测类别：1，实际类别：1
	模式 5 预测类别：1，实际类别：1
	模式 6 预测类别：1，实际类别：1
	模式 7 预测类别：0，实际类别：0
	模式 8 预测类别：0，实际类别：0
	模式 9 预测类别：0，实际类别：0

Good Job~ 效果不错~ 不过这只是对训练样本掌握得非常好罢了，该 LVQ 网络的泛化能力可能不会很好。